{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "\n",
    "from time import time # needed to measure the elapsed time\n",
    "from itertools import zip_longest\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_shingles(text, k=5):\n",
    "    words = text.split()\n",
    "    return set(zip_longest(*[words[i:] for i in range(k)], fillvalue=''))\n",
    "\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    return len(set1 & set2) / len(set1 | set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the answer to part 1 of the exercise\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the answer to part 1 of the exercise\\n\")\n",
    "\n",
    "# we read the train and the test datasets from the respective files\n",
    "train_ds_comma=pd.read_csv(\"train.csv\")\n",
    "test_ds_comma=pd.read_csv(\"test_without_labels.csv\")\n",
    "\n",
    "\n",
    "fraction=0.10 # the fraction of the datasets, used to create smaller, faster to work on datasets\n",
    "\n",
    "# Split the training dataset into a smaller one\n",
    "train_subset, _ = train_test_split(\n",
    "    train_ds_comma, \n",
    "    train_size=fraction, \n",
    "    stratify=train_ds_comma['Label'],  # Ensure stratified sampling\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_subset.to_csv('train_subset.csv', index=False)\n",
    "\n",
    "# Split the testing dataset into a smaller one\n",
    "test_subset=test_ds_comma.sample(frac=fraction,random_state=42)\n",
    "test_subset.to_csv('test_subset.csv',index=False)\n",
    "\n",
    "# the two sets that we are going to work on\n",
    "train_subset=pd.read_csv('train_subset.csv')\n",
    "test_subset=pd.read_csv('test_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: Random Forest\n",
      "\n",
      "Testing: SVM\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing, tokenization and removal of stop words via Vectorizer() of sklearn\n",
    "# This process is called vectorization, in which documents are transformed into numerical represantations\n",
    "# It was observed that TfidVectorizer works better in combination with LinearSVC, which is the recommended SVM method for large number of samples \n",
    "\n",
    "vctrz= TfidfVectorizer(stop_words='english')\n",
    "x_train=vctrz.fit_transform(train_subset['Title']+train_subset['Content'])\n",
    "y_train=train_subset['Label']\n",
    "x_test=vctrz.transform(test_subset['Title']+ test_subset['Content'])\n",
    "\n",
    "# The classifiers we are going to compare\n",
    "classifiers={'Random Forest': RandomForestClassifier(),\n",
    "            #  'SVM': SVC(),\n",
    "             'SVM':LinearSVC()}\n",
    "\n",
    "# the results of the comparison\n",
    "results={}\n",
    "\n",
    "# we iterate over the set of the classifiers and we perform cross validation\n",
    "for name,clfr in classifiers.items():\n",
    "    print(\"\\nTesting:\",name)\n",
    "    scores=cross_val_score(clfr,x_train,y_train,cv=5,scoring='accuracy')\n",
    "    results[name]=scores.mean() # the score of the validation of the classifier clfr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold cross validation of KNN\n",
    "if(fraction<=0.15):\n",
    "    skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    X=train_subset['Title']+train_subset['Content']\n",
    "    y=train_subset['Label']\n",
    "\n",
    "    accur=[]\n",
    "\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        # Split into train and validation sets\n",
    "        X_train_knn, X_val_knn = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train_knn, y_val_knn = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "\n",
    "\n",
    "        train_shingles = X_train_knn.apply(text_to_shingles)\n",
    "        val_shingles = X_val_knn.apply(text_to_shingles)\n",
    "\n",
    "        # Perform brute-force K-NN for validation\n",
    "        predictions = []\n",
    "        k=7\n",
    "        for val_doc in val_shingles:\n",
    "            similarities = [(i, jaccard_similarity(val_doc,train_doc))\n",
    "                                for i, train_doc in enumerate(train_shingles)]\n",
    "            similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "            # Majority voting\n",
    "            neighbor_labels = [y_train_knn.iloc[idx] for idx, _ in similarities]\n",
    "            majority_label = Counter(neighbor_labels).most_common(1)[0][0]\n",
    "            predictions.append(majority_label)\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy = accuracy_score(y_val_knn, predictions)\n",
    "        accur.append(accuracy)\n",
    "\n",
    "    knn_acc=np.mean(accur)\n",
    "else:\n",
    "    knn_acc=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Results for 10.0% of the two sets\n",
      "  ->Random Forest: 89.20305515201721 %\n",
      "  ->SVM: 95.50057429174021 %\n",
      "  ->kNN: 71.10631800954886 %\n",
      "The best method is: SVM\n"
     ]
    }
   ],
   "source": [
    "results['kNN']=knn_acc\n",
    "\n",
    "print(f\"5-Fold Cross-Validation Results for {fraction*100}% of the two sets\")\n",
    "for name,res in results.items():\n",
    "    if(res!=0):\n",
    "        print(f\"  ->{name}: {res*100} %\")\n",
    "\n",
    "# we sort the results we got in descending order, so that we can get the best method\n",
    "sorted_results=dict(sorted(results.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "# the best method, according to the 5-Fold Validation we performed\n",
    "best_fit_name= list(sorted_results.keys())[0]\n",
    "print(\"The best method is:\",best_fit_name)\n",
    "\n",
    "# we apply our best method on the training set\n",
    "best_fit_method=classifiers[best_fit_name]\n",
    "best_fit_method.fit(x_train,y_train)\n",
    "\n",
    "# we predict on the test set, using our best method\n",
    "test_subset['Predicted'] = best_fit_method.predict(x_test)\n",
    "test_subset[['Id', 'Predicted']].to_csv('testSet_categories.csv', index=False) # we output the predictions in the respective .csv fil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the stsrt of part 2\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the stsrt of part 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
